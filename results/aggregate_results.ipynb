{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch results aggregation\n",
    "\n",
    "### Content\n",
    "\n",
    "+ [1. Notebook description](#1.-Notebook-Description)\n",
    "+ [2. Aggregate and Export](#2.-aggregate-and-export)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notebook Description\n",
    "\n",
    "This notebook is used to import individual gridsearchcv result files and aggregate them into a large dataframe.\n",
    "Afterwards this dataframe will be exported to `csv`, in order to easily import the data with the plotting notebook, which uses an R Kernel.\n",
    "\n",
    "---\n",
    "\n",
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digits.utils import dotdict, getoutname, gettypename\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregate and Export\n",
    "\n",
    "Individual result files are saved in compressed numpy format.\n",
    "They contain the crossvalidation results for all individual instances of the meta search.\n",
    "To efficiently insert the data into a data frame I am filling up lists and then create the dataframe only at the very end. Appending to the dataframe would have a huge performance impact in this case and should be avoided.\n",
    "\n",
    "There are two objects in the numpy data file, `params` which contains the cv results and `data`, which contains the final testing score from a 10% holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_subj, s_type, s_kernel, s_score, s_test, s_d1, s_d2 = ([], [], [], [], [], [], [])\n",
    "\n",
    "for resfile in glob.glob('results/*.npz'):\n",
    "    objs = np.load(resfile)\n",
    "    results = dotdict(objs[\"results\"].reshape(-1)[0])\n",
    "    config = dotdict(objs[\"config\"].reshape(-1)[0])\n",
    "    params = results.params\n",
    "    data = results.data\n",
    "    typename = gettypename(config)\n",
    "\n",
    "    # we could just use params length, but this way we double check\n",
    "    for comb in combinations(np.arange(10), 2):\n",
    "        \n",
    "        # put each digit CV(!) score in the df, we can average when plotting\n",
    "        for cvscore in params[comb]:\n",
    "            s_subj.append(config['subject'])\n",
    "            s_type.append(typename)\n",
    "            kernel = 'none'\n",
    "            for param in cvscore.parameters:\n",
    "                if 'kernel' in param:\n",
    "                    kernel = cvscore.parameters[param]\n",
    "            s_kernel.append(kernel)\n",
    "            s_score.append(cvscore.mean_validation_score)\n",
    "            s_test.append(\"cv\")\n",
    "            s_d1.append(comb[0])\n",
    "            s_d2.append(comb[1])\n",
    "            \n",
    "        # final score, may be more than one (rbf+linear for instance)\n",
    "        for finalscore in data[comb]:\n",
    "            s_subj.append(config['subject'])\n",
    "            s_type.append(typename)\n",
    "            s_score.append(finalscore[0])\n",
    "            s_test.append(\"final\")\n",
    "            kernel = 'none'\n",
    "            for k,v in finalscore[1].items():\n",
    "                if 'kernel' in k:\n",
    "                    kernel = v\n",
    "            s_kernel.append(kernel)\n",
    "            s_d1.append(comb[0])\n",
    "            s_d2.append(comb[1])\n",
    "\n",
    "df = pd.DataFrame({\"subject\":s_subj, \"type\":s_type, \"score\":s_score,\n",
    "                   \"test\":s_test, 'd1':s_d1, 'd2':s_d2, 'kernel':s_kernel})\n",
    "df.to_csv(\"all_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
