{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate weight files\n",
    "\n",
    "### Content\n",
    "\n",
    "+ [1. Notebook description](#1.-Notebook-Description)\n",
    "+ [2. Generate Weights for best Classifiers](#2.-Generate-Weights-for-best-Classifiers)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notebook Description\n",
    "\n",
    "Given model configurations and input data we are fitting a fixed classifier on the whole dataset and save the `coef_` attribute of the estimator object to a new hdf5 file.\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "+ model config yaml files\n",
    "+ pre-transformed subject data for those models\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digits.utils import dotdict\n",
    "from digits.data import matimport, select, utils\n",
    "from digits.transform.dimreduction import SubsampleTransform, FFTransform\n",
    "from digits.transform.shaper import CSPFlatten, CSPWrap\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from os import path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FutureWarning in mne package that is just annoying..\n",
    "warnings.filterwarnings(\"ignore\", message=\"in the future, boolean array-likes will be handled as a boolean array index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Generate Weights for best Classifiers\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = [3130, 3131, 3132, 3134, 3135, 3136, 3138, 3146, 3147, 3149,\n",
    "            3154, 3156, 3157, 3158, 3159, 3161, 3162, 3233, 3237, 3239,\n",
    "            3240, 3241, 3242, 3243, 3245, 3248, 3250, 3251, 3252, 3253,\n",
    "            3255, 3260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best models\n",
    "models = {\n",
    "    'svc': ('short_lda_1.yaml', SVC(kernel='linear', C=1.274275e-06, cache_size=1024)),\n",
    "    'lda': ('short_lda_1.yaml', LDA(shrinkage=0.0444444444444, solver='lsqr')),\n",
    "    'ldacsp': ('short_lda_4.yaml', Pipeline([\n",
    "            ('wrap', CSPWrap()),\n",
    "            ('csp', CSP(n_components=6, reg='ledoit_wolf', transform_into='csp_space')),\n",
    "            ('flat', CSPFlatten()),\n",
    "            ('lda', LDA(solver='lsqr', shrinkage='auto'))\n",
    "        ]))\n",
    "}\n",
    "\n",
    "# a time domain model for the document\n",
    "models = {\n",
    "    'svc_t': ('short_nofft20.yaml', SVC(kernel='linear', C=1.274275e-06, cache_size=1024)),\n",
    "    'lda_t': ('short_nofft20.yaml', LDA(shrinkage=0.0444444444444, solver='lsqr')),\n",
    "    'ldacsp_t': ('short_nofft20.yaml', Pipeline([\n",
    "            ('wrap', CSPWrap()),\n",
    "            ('csp', CSP(n_components=6, reg='ledoit_wolf', transform_into='csp_space')),\n",
    "            ('flat', CSPFlatten()),\n",
    "            ('lda', LDA(solver='lsqr', shrinkage='auto'))\n",
    "        ]))\n",
    "}\n",
    "\n",
    "dataroot = '../../data/thomas/artcorr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clfname, (config_file, clf) in models.items():\n",
    "    with open('../../jobs/configs/'+config_file, 'r') as f:\n",
    "        config = dotdict(yaml.load(f)['config'])\n",
    "\n",
    "    print(\"------------------\\n{}\\n------------------\".format(clfname))\n",
    "    for subject in [str(x) for x in subjects]:\n",
    "        infile = subject+'_'+config_file+'.h5'\n",
    "        outfile = 'weights_'+clfname+'_'+subject+'.h5'\n",
    "        if path.exists(outfile):\n",
    "            print(\"skipping {}\".format(subject))\n",
    "            continue\n",
    "        print(\"running {}\".format(subject)) \n",
    "        print('{} -> {}'.format(infile,outfile))\n",
    "        store = pd.HDFStore(path.join(dataroot, 'transformed', infile))\n",
    "        samples = store['samples']\n",
    "        targets = store['targets']\n",
    "\n",
    "        weights = {}\n",
    "        for dix,(d1,d2) in enumerate(combinations(np.arange(10), 2)):\n",
    "\n",
    "            tmp_samples, tmp_targets = select.fromtargetlist(samples, targets, [d1, d2])\n",
    "            \n",
    "            clf.fit(tmp_samples, tmp_targets['label'])\n",
    "\n",
    "            if 'ldacsp' in clfname:\n",
    "                weights[(clfname, d1, d2)] = clf.named_steps['lda'].coef_[0]\n",
    "            else:\n",
    "                weights[(clfname, d1, d2)] = clf.coef_[0]\n",
    "        \n",
    "        df_weights = pd.DataFrame(weights)\n",
    "        df_weights.columns.names = ['type', 'd1', 'd2']\n",
    "        df_weights.index.names = ['weights']\n",
    "        store = pd.HDFStore(outfile)\n",
    "        store['weights'] = df_weights\n",
    "        store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
