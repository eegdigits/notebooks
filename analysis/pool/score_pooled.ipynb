{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score pooled data\n",
    "\n",
    "### Content\n",
    "\n",
    "+ [1. Notebook description](#1.-Notebook-Description)\n",
    "+ [2. Specify models](#2.-specify-models)\n",
    "+ [3. Run crossvalidations](#3.-run-crossvalidations)\n",
    "+ [4. Export](#4.exports)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notebook Description\n",
    "\n",
    "Using the notebook that extracted the best meta parameters we can now instantiate a specific classifier instance and run a single 10-fold cross-validation on the pooled dataset that corresponds to the model's transformation scheme.\n",
    "\n",
    "---\n",
    "\n",
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from digits.data import select\n",
    "from digits.transform.shaper import CSPFlatten, CSPWrap\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from mne import create_info, EvokedArray\n",
    "from mne.viz import plot_topomap, plot_layout, plot_montage\n",
    "from mne.channels import make_eeg_layout\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Specify models\n",
    "\n",
    "A model has a name and consists of a transformation scheme and a classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'svc': ('short_lda_1.yaml', SVC(kernel='linear', C=1.274275e-06, cache_size=1024)),\n",
    "    'lda': ('short_lda_1.yaml', LDA(shrinkage=0.0444444444444, solver='lsqr')),\n",
    "    'ldacsp': ('short_lda_4.yaml', Pipeline([\n",
    "            ('wrap', CSPWrap()),\n",
    "            ('csp', CSP(n_components=6, reg='ledoit_wolf', transform_into='csp_space')),\n",
    "            ('flat', CSPFlatten()),\n",
    "            ('lda', LDA(solver='lsqr', shrinkage='auto'))\n",
    "        ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basepath = '../../data/thomas/artcorr/imported'\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run crossvalidations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clfname, (config_file, clf) in models.items():\n",
    "    \n",
    "    store = pd.HDFStore(path.join(basepath, config_file+'.h5'))\n",
    "    samples = store['samples']\n",
    "    targets = store['targets']\n",
    "    \n",
    "    for dix,(d1,d2) in enumerate(combinations(np.arange(10), 2)):\n",
    "        print(\"running {} [{},{}]\".format(clfname, d1,d2))\n",
    "\n",
    "        tmp_samples, tmp_targets = select.fromtargetlist(samples, targets, [d1, d2])\n",
    "        \n",
    "        scores[(clfname, d1, d2)] = cross_val_score(clf, tmp_samples,\n",
    "                                                    tmp_targets['label'], cv=10,\n",
    "                                                    verbose=1, n_jobs=-1)\n",
    "        \n",
    "        print(len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = 'results_pooled_final.h5'\n",
    "store = pd.HDFStore(outfile)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores.columns.names = ['type', 'd1','d2']\n",
    "df_scores.index.names = ['crossvalidation']\n",
    "store['scores'] = df_scores\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### long format for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1s, d2s, subjects, groups, scores, tests= [], [], [], [], [], []\n",
    "for (group, d1, d2), values in data.iteritems():\n",
    "    for score in values:\n",
    "        groups.append(group)\n",
    "        d1s.append(d1)\n",
    "        d2s.append(d2)\n",
    "        subjects.append('pooled')\n",
    "        tests.append('cv')\n",
    "        scores.append(score)\n",
    "\n",
    "dflong = pd.DataFrame({'group': groups, 'd1': d1s, 'd2': d2s,\n",
    "                       'subject': subjects, 'test': tests, 'score': scores})\n",
    "dflong.to_csv('results_pooled_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
